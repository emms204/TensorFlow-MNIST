{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdFLDI7_mWV2"
      },
      "source": [
        "# Deep Neural Network for MNIST Classification\n",
        "\n",
        "We'll apply all the knowledge from the lectures in this section to write a deep neural network. The problem we've chosen is referred to as the \"Hello World\" of deep learning because for most students it is the first deep learning algorithm they see.\n",
        "\n",
        "The dataset is called MNIST and refers to handwritten digit recognition. You can find more about it on Yann LeCun's website (Director of AI Research, Facebook). He is one of the pioneers of what we've been talking about and of more complex approaches that are widely used today, such as covolutional neural networks (CNNs). \n",
        "\n",
        "The dataset provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image). \n",
        "\n",
        "The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes. \n",
        "\n",
        "Our goal would be to build a neural network with 2 hidden layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf7U-s2emWWN"
      },
      "source": [
        "## Import the relevant packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpCCl21jmWWS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POFipkNZmWWa"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "jORQABsimWWi"
      },
      "outputs": [],
      "source": [
        "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "\n",
        "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
        "\n",
        "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
        "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
        "\n",
        "num_test_samples = mnist_info.splits['test'].num_examples\n",
        "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
        "\n",
        "\n",
        "def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255.\n",
        "    return image, label\n",
        "\n",
        "\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,logs={}):\n",
        "    if((logs.get('accuracy') != None) and (logs.get('accuracy')> 1.00)):\n",
        "      print(\"\\nReached 99.8% accuracy so cancelling training!\")\n",
        "      self.model.stop_training=True\n",
        "callbacks = MyCallback()\n",
        "scaled_train_and_validation_data = mnist_train.map(scale)\n",
        "\n",
        "test_data = mnist_test.map(scale)\n",
        "\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "shuffled_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
        "\n",
        "validation_data = shuffled_train_and_validation_data.take(num_validation_samples)\n",
        "train_data = shuffled_train_and_validation_data.skip(num_validation_samples)\n",
        "\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "train_data = train_data.batch(BATCH_SIZE)\n",
        "validation_data = validation_data.batch(num_validation_samples)\n",
        "test_data = test_data.batch(num_test_samples)\n",
        "\n",
        "validation_inputs, validation_targets = next(iter(validation_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-v0ZRGMmWWl"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1qSnwCSmWWq"
      },
      "source": [
        "### Outline the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "7I_8GEHHmWWr"
      },
      "outputs": [],
      "source": [
        "input_size = 784\n",
        "output_size = 10\n",
        "hidden_layer_size = 50\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28,1)),\n",
        "                             tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                             tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "                             tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                             tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "                             tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
        "                             tf.keras.layers.Dense(output_size, activation='softmax')   \n",
        "                            ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFDdg8eTmWWu"
      },
      "source": [
        "### Choose the optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "6r111OSxmWWx"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdDROmosmWWz"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9agFna30mWW0",
        "outputId": "4c69194e-201b-4533-93bc-8f58851bb937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "540/540 - 48s - loss: 0.2922 - accuracy: 0.9129 - val_loss: 0.0797 - val_accuracy: 0.9775 - 48s/epoch - 89ms/step\n",
            "Epoch 2/20\n",
            "540/540 - 42s - loss: 0.0729 - accuracy: 0.9769 - val_loss: 0.0648 - val_accuracy: 0.9805 - 42s/epoch - 79ms/step\n",
            "Epoch 3/20\n",
            "540/540 - 42s - loss: 0.0543 - accuracy: 0.9834 - val_loss: 0.0478 - val_accuracy: 0.9853 - 42s/epoch - 78ms/step\n",
            "Epoch 4/20\n",
            "540/540 - 42s - loss: 0.0417 - accuracy: 0.9869 - val_loss: 0.0376 - val_accuracy: 0.9893 - 42s/epoch - 78ms/step\n",
            "Epoch 5/20\n",
            "540/540 - 42s - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.0352 - val_accuracy: 0.9892 - 42s/epoch - 78ms/step\n",
            "Epoch 6/20\n",
            "540/540 - 42s - loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.0320 - val_accuracy: 0.9897 - 42s/epoch - 78ms/step\n",
            "Epoch 7/20\n",
            "540/540 - 43s - loss: 0.0249 - accuracy: 0.9923 - val_loss: 0.0327 - val_accuracy: 0.9902 - 43s/epoch - 79ms/step\n",
            "Epoch 8/20\n",
            "540/540 - 42s - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.0293 - val_accuracy: 0.9898 - 42s/epoch - 78ms/step\n",
            "Epoch 9/20\n",
            "540/540 - 43s - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.0267 - val_accuracy: 0.9920 - 43s/epoch - 79ms/step\n",
            "Epoch 10/20\n",
            "540/540 - 42s - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.0199 - val_accuracy: 0.9945 - 42s/epoch - 78ms/step\n",
            "Epoch 11/20\n",
            "540/540 - 42s - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.0198 - val_accuracy: 0.9938 - 42s/epoch - 78ms/step\n",
            "Epoch 12/20\n",
            "540/540 - 43s - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0218 - val_accuracy: 0.9932 - 43s/epoch - 79ms/step\n",
            "Epoch 13/20\n",
            "540/540 - 42s - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.0183 - val_accuracy: 0.9947 - 42s/epoch - 78ms/step\n",
            "Epoch 14/20\n",
            "540/540 - 43s - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.0182 - val_accuracy: 0.9948 - 43s/epoch - 79ms/step\n",
            "Epoch 15/20\n",
            "540/540 - 42s - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0144 - val_accuracy: 0.9948 - 42s/epoch - 78ms/step\n",
            "Epoch 16/20\n",
            "540/540 - 42s - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0129 - val_accuracy: 0.9957 - 42s/epoch - 79ms/step\n",
            "Epoch 17/20\n",
            "540/540 - 42s - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0084 - val_accuracy: 0.9967 - 42s/epoch - 78ms/step\n",
            "Epoch 18/20\n",
            "540/540 - 42s - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0149 - val_accuracy: 0.9948 - 42s/epoch - 78ms/step\n",
            "Epoch 19/20\n",
            "540/540 - 42s - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.0089 - val_accuracy: 0.9963 - 42s/epoch - 79ms/step\n",
            "Epoch 20/20\n",
            "540/540 - 42s - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0078 - val_accuracy: 0.9962 - 42s/epoch - 79ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb3a79ab0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "model.fit(train_data, epochs = NUM_EPOCHS, validation_data=(validation_inputs, validation_targets), verbose=2, callbacks=[MyCallback()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uEtmpWCmWW4"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zDu6Qe3mWW6",
        "outputId": "5baad134-fc2a-42d7-9502-ef1d49bc9d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 7s 7s/step - loss: 0.0306 - accuracy: 0.9909\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtSXdzLsmWW8",
        "outputId": "fb2a6995-a6a3-4130-fc49-a377e579ee85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.03. Test accuracy: 99.09%\n"
          ]
        }
      ],
      "source": [
        "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AOLOhJ3hoQsC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TensorFlow_MNIST_complete.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}